Jennifer Lin
CS111 Project 2A

Description of included files:
	    lab2_add.c: C program that implements a shared variable add function
	    		that takes options like --threads, --iterations, --yield,
			and --sync.
	    SortedList.h: header file provided in the spec that describes the
	    		  interface of 4 linked list operations
	    SortedList.c: C program that implements 4 functions: insert, delete,
	    		  lookup, and length for a sorted doubly linkedlist
 	    lab2_list.c: C program that takes options like --threads, --iterations,
	    		 --yield, --sync
	    Makefile: build all deliverable programs, create graphs required by the spec
	    	      using test data generated by make tests, make clean, and make tarball
		      with all required files for this assignment
	    lab2_add.csv: results for running make tests on part 1
	    lab2_list.csv: results for running make tests on part 2
	    *.png: graph files required in the spec, generated from make graphs
	    README.txt: brief description of included files and answers to spec questions

Ques 2.1.1: This is because when there are more iterations, each thread
will access the same variable more times, which increases the chances of
a race condition happening which leads to failure. When it's the case of
a single thread however, there won't be a failure because only one thread
is using the resources, thus a race condition will not happen.

Ques 2.1.2: The --yield runs slower because of context switches. It calls
pthread_yield() and spends more time with privileges instructions that change
thread states between running and ready. It is not possible to get valid
per-operation timings with yield because it is not possible to remove all
context switches.

Ques 2.1.3: The average cost per operation drop with increasing iterations
because the fixed time overhead is distributed among each operation, leading
to a lower average cost per operation. Since the average cost per operation
drops with increasing iterations, we can correctly measure the cost per
operation by setting up the timer after we're done with creating threads.

Ques 2.1.4: All options perform similarly for low numbers of threads because
the possibility of race conditions and conflicts are lower. Thus, the protecting
mechanisms do not play a great role in these situations. However, when we increase
the number of threads, the possibility of race conditions will be higher, therefore
locking mechanisms will be invoked, protecting the operations, and thus slow down.
Spin locks are expensive for large number of threads because spin locks keep
spinning until the lock is released by another thread. Spin lock operations do not
sleep, therefore it will waste a lot of CPU time and is very expensive.

Ques 2.2.1: First of all, the operations in part 1 are much more simple, which
simply involve the addition and subtraction of 1. In part 2 however, we have
operations including searching, deleting a linkedlist...etc, thus,
the critical section of part 2 is longer than part 1, the lock is
held much longer, causing conflicts to be more likely to happen. Moreover, since
part 2 results in the possibility of more conflicts and blocked threads, there will
be less parallelism.

Ques 2.2.2: In part 1 for mutex, the time per protected operation decreases as
the number of thread increases. For spin however, the time actually increases as
the number of thread increases. In part 2, both mutex and spin have a increasing
time per protected operation as the number of thread increases. This is probably
because of part 2's longer critical section as mentioned in the previous question.
Because of this, locks are held much longer and more time is spent blocking,
which results in the increasing number of time per protected operation for both
spin and mutex.

Problems: For part 2, I had to comment out the last few lines of tests in Makefile
	  because the program runs forever like an infinite loop. This is perhaps
	  because of race conditions and corrupted lists. Therefore some data are
	  missing, resulting in graphs with few data points.
